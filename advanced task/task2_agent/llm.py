import requests
import re
import os
from openai import OpenAI
from tavily import TavilyClient
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# system_prompt init
AGENT_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œå¹¶ä½¿ç”¨å¯ç”¨å·¥å…·ä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚

# å¯ç”¨å·¥å…·:
- `get_weather(city: str)`: æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ã€‚
- `get_attraction(city: str, weather: str)`: æ ¹æ®åŸå¸‚å’Œå¤©æ°”æœç´¢æ¨èçš„æ—…æ¸¸æ™¯ç‚¹ã€‚

# è¡ŒåŠ¨æ ¼å¼:
ä½ çš„å›ç­”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ã€‚é¦–å…ˆæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç„¶åæ˜¯ä½ è¦æ‰§è¡Œçš„å…·ä½“è¡ŒåŠ¨ï¼Œæ¯æ¬¡å›å¤åªè¾“å‡ºä¸€å¯¹Thought-Actionï¼š
Thought: [è¿™é‡Œæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œä¸‹ä¸€æ­¥è®¡åˆ’]
Action: [è¿™é‡Œæ˜¯ä½ è¦è°ƒç”¨çš„å·¥å…·ï¼Œæ ¼å¼ä¸º function_name(arg_name="arg_value")]

# æ”¶é›†ç”¨æˆ·ä¿¡æ¯ï¼š
å½“ä½ æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯èƒ½å›å¤ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨`Action:`å­—æ®µåä½¿ç”¨ `query(answer="...")` æ¥è¾“å‡ºè¯¢é—®ç”¨æˆ·çš„é—®é¢˜ã€‚

# ä»»åŠ¡å®Œæˆ:
å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨`Action:`å­—æ®µåä½¿ç”¨ `finish(answer="...")` æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

# åæ€æœºåˆ¶ï¼š
å¦‚æœ Observation ä¸­åŒ…å«ç”¨æˆ·çš„ä¸æ»¡æ„åé¦ˆï¼Œä½ å¿…é¡»åœ¨ä¸‹ä¸€æ¬¡ Thought ä¸­é¦–å…ˆåˆ†æä¸ºä»€ä¹ˆä¹‹å‰çš„æ¨èå¤±è´¥äº†ï¼Œå¹¶åœ¨ Action ä¸­ä½“ç°å‡ºç­–ç•¥çš„æ”¹å˜ã€‚

#æ³¨æ„äº‹é¡¹ï¼šå¦‚æœé‡åˆ°ç½‘ç»œé—®é¢˜ä¸èƒ½æŸ¥è¯¢å¤©æ°”ï¼Œè¯·ç¤¼è²Œåœ°å‘ŠçŸ¥ç”¨æˆ·ï¼Œå¹¶ä¸”ç»§ç»­æ¨èæ™¯ç‚¹ã€‚å¦‚æœé‡åˆ°æ™¯åŒºæ— æ³•æ­£å¸¸è¿›å…¥ï¼Œå¦‚ç¥¨å”®ç½„ç­‰æƒ…å†µï¼Œè¯·åŠæ—¶è°ƒæ•´æ¨èæ–¹æ¡ˆã€‚

è¯·å¼€å§‹å§ï¼
"""


# LLM init
class OpenAICompatibleClient:
    """
    ä¸€ä¸ªç”¨äºè°ƒç”¨ä»»ä½•å…¼å®¹OpenAIæ¥å£çš„LLMæœåŠ¡çš„å®¢æˆ·ç«¯ã€‚
    """

    def __init__(self, model: str, api_key: str, base_url: str):
        self.model = model
        self.client = OpenAI(api_key=api_key, base_url=base_url)

    def generate(self, messages: list) -> str:
        """è°ƒç”¨LLM APIæ¥ç”Ÿæˆå›åº”ã€‚"""
        print("æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,  # è¿™é‡Œæ¢æˆäº†å¸¦æœ‰åŸºäºçš„åˆ—è¡¨
                stream=False,
            )
            answer = response.choices[0].message.content
            print("å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚")
            return answer
        except Exception as e:
            print(f"è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return "é”™è¯¯:è°ƒç”¨è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶å‡ºé”™ã€‚"


def get_weather(city: str) -> str:
    """
    é€šè¿‡è°ƒç”¨ wttr.in API æŸ¥è¯¢çœŸå®çš„å¤©æ°”ä¿¡æ¯ã€‚
    """
    # APIç«¯ç‚¹ï¼Œæˆ‘ä»¬è¯·æ±‚JSONæ ¼å¼çš„æ•°æ®
    url = f"https://wttr.in/{city}?format=j1"

    try:
        # å‘èµ·ç½‘ç»œè¯·æ±‚
        response = requests.get(url)
        # æ£€æŸ¥å“åº”çŠ¶æ€ç æ˜¯å¦ä¸º200 (æˆåŠŸ)
        response.raise_for_status()
        # è§£æè¿”å›çš„JSONæ•°æ®
        data = response.json()

        # æå–å½“å‰å¤©æ°”çŠ¶å†µ
        current_condition = data["current_condition"][0]
        weather_desc = current_condition["weatherDesc"][0]["value"]
        temp_c = current_condition["temp_C"]

        # æ ¼å¼åŒ–æˆè‡ªç„¶è¯­è¨€è¿”å›
        return f"{city}å½“å‰å¤©æ°”:{weather_desc}ï¼Œæ°”æ¸©{temp_c}æ‘„æ°åº¦"

    except requests.exceptions.RequestException as e:
        # å¤„ç†ç½‘ç»œé”™è¯¯
        return f"é”™è¯¯:æŸ¥è¯¢å¤©æ°”æ—¶é‡åˆ°ç½‘ç»œé—®é¢˜ - {e}"
    except (KeyError, IndexError) as e:
        # å¤„ç†æ•°æ®è§£æé”™è¯¯
        return f"é”™è¯¯:è§£æå¤©æ°”æ•°æ®å¤±è´¥ï¼Œå¯èƒ½æ˜¯åŸå¸‚åç§°æ— æ•ˆ - {e}"


def get_attraction(city: str, weather: str) -> str:
    api_key = os.getenv("TAVILY_API_KEY")
    if not api_key:
        return "é”™è¯¯: æœªæ‰¾åˆ° TAVILY_API_KEY ç¯å¢ƒå˜é‡ã€‚è¯·è®¾ç½®è¯¥ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨æ—…æ¸¸æ™¯ç‚¹æ¨èåŠŸèƒ½ã€‚"
    tavily = TavilyClient(api_key=api_key)
    query = f"'{city}'{weather}'å¤©æ°”ä¸‹æœ€å€¼å¾—å»çš„æ—…æ¸¸æ™¯ç‚¹æ¨èç†ç”±"
    try:
        # include_answer=True è¡¨ç¤ºè¿”å›ç»¼åˆæ€§å›ç­”
        responses = tavily.search(
            query=query, search_depth="basic", include_answer=True
        )
        if responses.get("answers"):
            return responses["answers"]

        # è‹¥æ²¡æœ‰ç»¼åˆæ€§å›ç­”,æ ¼å¼åŒ–åŸå§‹ç»“æœ
        formatted_results = []
        for result in responses.get("result", []):
            formatted_results.append(f"-{result['title']}:{result['content']}")
            # FIXME:æ‰“å°çœ‹çœ‹æ˜¯ä»€ä¹ˆä¸œè¥¿
            # print(formatted_results)
        if not formatted_results:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ—…æ¸¸æ™¯ç‚¹æ¨èã€‚"
        return "æ ¹æ®æœç´¢ï¼Œä¸ºä½ æ‰¾åˆ°ä¸€ä¸‹ä¿¡æ¯ï¼š\n" + "\n".join(formatted_results)

    except Exception as e:
        return f"é”™è¯¯:æ‰§è¡ŒTavilyæœç´¢æ—¶å‡ºç°é—®é¢˜ - {e}"


# skills dictionary
skills = {"get_weather": get_weather, "get_attraction": get_attraction}

if __name__ == "__main__":
    # initialize LLM client
    load_dotenv()
    llm = OpenAICompatibleClient(
        model="deepseek-chat",
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com/v1",
    )

    # welcome message
    print("æ¬¢è¿ä½¿ç”¨æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ï¼")

    # initialize user memory
    user_memory = {
        "preference": "å–œæ¬¢å†å²æ–‡åŒ–æ™¯ç‚¹",
        "budget": "ä¸­ç­‰é¢„ç®—",
        "history_rejections": [],  # è®°å½•ç”¨æˆ·æ‹’ç»è¿‡çš„æ™¯ç‚¹
    }
    user_query = input("\nâœ¨ è¯·è¾“å…¥æ‚¨çš„æ—…è¡Œç›¸å…³é—®é¢˜ :")
    # initialize chat history
    chat_history = [
        {
            "role": "system",
            "content": AGENT_SYSTEM_PROMPT
            + f"\nç”¨æˆ·å‘æ—…è¡Œåå¥½æ˜¯:{user_memory['preference']}",
        },
        {"role": "user", "content": user_query},
    ]
    # å¼€å§‹æ ‡è®°
    START_flag = False
    # è®°å½•ä¸æ»¡æ„çš„æ¬¡æ•°
    UNSATISFIED_flag = 0
    while True:
        if START_flag:
            user_query = input("\nâœ¨ è¯·è¾“å…¥æ‚¨çš„æ—…è¡Œç›¸å…³é—®é¢˜ :")
            # è®°å½•è§‚å¯Ÿç»“æœ
            chat_history.append({"role": "user", "content": user_query})
            if user_query.lower() in ["exit", "quit", "é€€å‡º"]:
                print("\nâœ¨ å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼")
                break
        else:
            START_flag = True

        # interaction loop
        for i in range(100):
            """
            è¿è¡Œçš„é€»è¾‘å‚è€ƒäº†ç»™çš„ä»£ç æ¨¡æ¿ï¼Œä½†æ˜¯æœ‰æ”¹åŠ¨ï¼Œå…·ä½“çš„é€»è¾‘å¦‚ä¸‹ï¼š
            - ä½¿ç”¨ChatPromptTemplateæ¥å®šä¹‰promptæ¨¡æ¿ï¼Œä½¿ç”¨listæ•°æ®ç»“æ„æ¥å®ç°èŠå¤©è®°å½•çš„å­˜å‚¨ï¼Œå®ç°è®°å½•ä¸Šä¸‹æ–‡åŠŸèƒ½
            - è°ƒç”¨LLMï¼Œè¿™é‡Œæˆ‘ä½¿ç”¨çš„æ˜¯deepseekçš„API
            - è§£æActionå¹¶æ‰§è¡Œå·¥å…·ï¼Œè¿™é‡Œæ²¿ç”¨äº†datawhaleç»™çš„ä»£ç æ¨¡æ¿
              - æ‰§è¡Œå·¥å…·è·å¾—ç»“æœ
              -å°†å·¥å…·çš„è§‚å¯Ÿç»“æœä½œä¸ºç”¨æˆ·åé¦ˆå­˜å…¥å†å²è®°å½•

            - æ ¸å¿ƒé€»è¾‘åˆå§‹åŒ–ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ -> è¿›å…¥å¾ªç¯ ->å¤„ç†è¾“å‡ºæ ¼å¼-> ç”Ÿæˆ Prompt -> è·å– AI å›å¤ -> è·å–å·¥å…·ç»“æœ -> è¿½åŠ åˆ°åˆ—è¡¨ -> ä¸‹ä¸€è½®
            """
            print(f"--- å¾ªç¯ {i+1} ---\n")

            # æ„å»ºæç¤ºè¯
            # è¿™é‡Œè¿”å›çš„æ˜¯ä¸€ä¸ªTemplateå¯¹è±¡
            prompt_template = ChatPromptTemplate.from_messages(chat_history)

            # è½¬æ¢ä¸º LangChain æ¶ˆæ¯å¯¹è±¡
            lc_messages = prompt_template.format_messages()

            messages = []
            for msg in lc_messages:
                # å®šä¹‰è§’è‰²æ˜ å°„å…³ç³»
                role_map = {"human": "user", "ai": "assistant", "system": "system"}
                # å¦‚æœæ˜¯ LangChain çš„ AIMessageï¼Œmsg.type æ˜¯ 'ai'ï¼Œéœ€è½¬ä¸º 'assistant'
                messages.append(
                    {"role": role_map.get(msg.type, "user"), "content": msg.content}
                )

            # è°ƒç”¨LLMç”Ÿæˆå›åº”
            response = llm.generate(messages)
            # å¤„ç†å¤šä½™è¾“å‡ºçš„thought-Action
            match = re.search(
                r"(Thought:.*?Action:.*?)(?=\n\s*(?:Thought:|Action:|Observation:)|\Z)",
                response,
                re.DOTALL,
            )
            if match:
                truncated = match.group(1).strip()
                if truncated != response.strip():
                    response = truncated
                    print("å·²æˆªæ–­å¤šä½™çš„ Thought-Action å¯¹")
            print(f"æ¨¡å‹è¾“å‡º:\n{response}\n")
            # FIXME:
            # print(response)
            chat_history.append({"role": "assistant", "content": response})

            # è§£æå¹¶æ‰§è¡Œè¡ŒåŠ¨
            action_match = re.search(r"Action: (.*)", response, re.DOTALL)
            if not action_match:
                print("è§£æé”™è¯¯:æ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° Actionã€‚")
                break
            action_str = action_match.group(1).strip()

            # è¯¢é—®ç”¨æˆ·ç¯èŠ‚
            if action_str.startswith("query"):
                final_answer = re.search(r'query\(answer="(.*)"\)', action_str).group(1)
                print(f"\nâœ¨ æ™ºèƒ½åŠ©æ‰‹: {final_answer}")
                query_data = input("\nè¯·æ‚¨å›ç­”:")
                chat_history.append(
                    {"role": "user", "content": f"Observation: {query_data}"}
                )
                break

            # æœ€ç»ˆå›ç­”ç¯èŠ‚
            if action_str.startswith("finish"):
                final_answer = re.search(r'finish\(answer="(.*)"\)', action_str).group(
                    1
                )
                print(f"\nâœ¨ æ™ºèƒ½åŠ©æ‰‹å›ç­”: {final_answer}")
                # å®ç°è¯¢é—®ç”¨æˆ·æ˜¯å¦æ»¡æ„
                feedback = input("\næ‚¨å¯¹è¿™ä¸ªå»ºè®®è¿˜æ»¡æ„å—?(æ»¡æ„/ä¸æ»¡æ„)")
                if "ä¸æ»¡æ„" in feedback:
                    UNSATISFIED_flag += 1
                    # è®©ç”¨æˆ·è¯´å‡ºåŸå› 
                    reason = input("èƒ½å‘Šè¯‰æˆ‘ä¸æ»¡æ„çš„å…·ä½“åŸå› å—ï¼Ÿ")
                    # æ›´æ–°é•¿æœŸè®°å¿†
                    user_memory["preference"] += f"æ¨èæ—¶é¿å¼€è¿™äº›å› ç´ ï¼š{reason}"
                    chat_history.append(
                        {"role": "user", "content": f"Observation: {reason}"}
                    )
                    print(
                        f"âœ¨ å·²è®°å½•æ‚¨çš„åå¥½ã€‚ä¸‹æ¬¡æˆ‘ä¼šæ³¨æ„ï¼Œæˆ‘å°†ä¸ºæ‚¨é‡æ–°æ¨èä¸€ä¸ªæ™¯ç‚¹ï¼Œè‹¥è¦é€€å‡ºæœ¬æ¬¡å¯¹è¯è¯·å›å¤exitã€quitã€é€€å‡ºä¸‰è€…å…¶ä¸€"
                    )
                    if UNSATISFIED_flag >= 3:
                        new_system_content = (
                            AGENT_SYSTEM_PROMPT
                            + "\nã€é‡è¦åæ€ã€‘ï¼šç”¨æˆ·å·²è¿ç»­å¤šæ¬¡ä¸æ»¡æ„ï¼è¯·å½»åº•æ”¾å¼ƒä¹‹å‰çš„æ¨èæ€è·¯ï¼Œå°è¯•æ›´ç‹¬ç‰¹æˆ–æ›´ç¬¦åˆç”¨æˆ·é¿é›·è¦æ±‚çš„æ–¹æ¡ˆã€‚"
                        )
                        if chat_history[0]["role"] == "system":
                            chat_history[0]["content"] = new_system_content
                else:
                    print("âœ¨ğŸ˜Š å¤ªæ£’äº†ï¼å¾ˆé«˜å…´èƒ½å¸®åˆ°æ‚¨ã€‚")

                break

            tool_name = re.search(r"(\w+)\(", action_str).group(1)
            args_str = re.search(r"\((.*)\)", action_str).group(1)
            kwargs = dict(re.findall(r'(\w+)="([^"]*)"', args_str))

            if tool_name in skills:
                observation = skills[tool_name](**kwargs)
            else:
                observation = f"é”™è¯¯:æœªå®šä¹‰çš„å·¥å…· '{tool_name}'"

            # è®°å½•è§‚å¯Ÿç»“æœ
            chat_history.append(
                {"role": "user", "content": f"Observation: {observation}"}
            )
